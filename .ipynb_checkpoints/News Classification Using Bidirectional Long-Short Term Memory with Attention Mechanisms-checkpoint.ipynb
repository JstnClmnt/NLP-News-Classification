{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing, Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = dirName+\"/\"+entry\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dirName = 'data';\n",
    "    \n",
    "# Get the list of all files in directory tree at given path\n",
    "listOfFiles = getListOfFiles(dirName)\n",
    "    \n",
    "\n",
    "df=pd.DataFrame(columns=[\"Title\",\"Description\",\"Category\"])\n",
    "# Print the files    \n",
    "\n",
    "for elem in listOfFiles:\n",
    "    file1 = open(elem,\"r\") \n",
    "    sampleNews=file1.read().split(\"\\n\")\n",
    "    newsDesc=\"\"\n",
    "    for strline in sampleNews[1:len(sampleNews)]:\n",
    "        newsDesc+=strline\n",
    "    \"\"\"\n",
    "    print(\"Category: \"+elem.split(\"/\")[1])\n",
    "    print(\"Title:\"+sampleNews[0])\n",
    "    print(\"Description:\"+newsDesc[0:50])\n",
    "    \"\"\"\n",
    "    dfsample=pd.DataFrame(columns=[\"Title\",\"Description\",\"Category\"],data=[[sampleNews[0],newsDesc,elem.split(\"/\")[1]]])\n",
    "    df=df.append(dfsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL\\'s underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL\\'s existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.Time Warner\\'s fourth quarter profits were slightly better than analysts\\' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann\\'s purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.reset_index()\n",
    "df=df.drop(list(df)[0], axis=1)\n",
    "df[\"Description\"].head()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuko...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices fo...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Domec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0  Ad sales boost Time Warner profit   \n",
       "1   Dollar gains on Greenspan speech   \n",
       "2  Yukos unit buyer faces loan claim   \n",
       "3  High fuel prices hit BA's profits   \n",
       "4  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                         Description  Category  \n",
       "0  Quarterly profits at US media giant TimeWarner...  business  \n",
       "1  The dollar has hit its highest level against t...  business  \n",
       "2  The owners of embattled Russian oil giant Yuko...  business  \n",
       "3  British Airways has blamed high fuel prices fo...  business  \n",
       "4  Shares in UK drinks and food firm Allied Domec...  business  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}\n",
      "business: 510\n",
      "entertainment: 386\n",
      "politics: 417\n",
      "sport: 511\n",
      "tech: 401\n"
     ]
    }
   ],
   "source": [
    "categories=df[\"Category\"].unique().tolist()\n",
    "cat_dict=dict(zip(categories, range(0,len((categories)))))\n",
    "print(cat_dict)\n",
    "for x in categories:\n",
    "    print(x+\": \"+str(len(df[df[\"Category\"]==x])))\n",
    "df[\"Category\"]=df['Category'].map(cat_dict, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quarterly profits at US media giant TimeWarner jumped     to      bn       m  for the three months to December  from     m year earlier The firm  which is now one of the biggest investors in Google  benefited from sales of high speed internet connections and higher advert sales  TimeWarner said fourth quarter sales rose    to      bn from      bn  Its profits were buoyed by one off gains which offset a profit dip at Warner Bros  and less users for AOL Time Warner said on Friday that it now owns    of search engine Google  But its own internet business  AOL  had has mixed fortunes  It lost         subscribers in the fourth quarter profits were lower than in the preceding three quarters  However  the company said AOL s underlying profit before exceptional items rose    on the back of stronger internet advertising revenues  It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL s existing customers for high speed broadband  TimeWarner also has to restate      and      results following a probe by the US Securities Exchange Commission  SEC   which is close to concluding Time Warner s fourth quarter profits were slightly better than analysts  expectations  But its film division saw profits slump     to     m  helped by box office flops Alexander and Catwoman  a sharp contrast to year earlier  when the third and final film in the Lord of the Rings trilogy boosted results  For the full year  TimeWarner posted a profit of      bn  up     from its      performance  while revenues grew      to       bn   Our financial performance was strong  meeting or exceeding all of our full year objectives and greatly enhancing our flexibility   chairman and chief executive Richard Parsons said  For       TimeWarner is projecting operating earnings growth of around     and also expects higher revenue and wider profit margins TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators  It has already offered to pay     m to settle charges  in a deal that is under review by the SEC  The company said it was unable to estimate the amount it needed to set aside for legal reserves  which it previously set at     m  It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann s purchase of a stake in AOL Europe  which it had reported as advertising revenue  It will now book the sale of its stake in AOL Europe as a loss on the value of that stake '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Description'] = df['Description'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "df=df.dropna()\n",
    "df[\"Description\"].head()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business: 395\n",
      "entertainment: 314\n",
      "politics: 341\n",
      "sport: 409\n",
      "tech: 321\n",
      "Total Training Data: 1780\n",
      "\n",
      "business: 115\n",
      "entertainment: 72\n",
      "politics: 76\n",
      "sport: 102\n",
      "tech: 80\n",
      "Total Test Data: 445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(df[\"Description\"], df[\"Category\"], test_size=0.20, random_state=42)\n",
    "\n",
    "train_sum=0\n",
    "for x in categories:\n",
    "    print(x+\": \"+str(len(y_train[y_train==cat_dict[x]])))\n",
    "    train_sum+=len(y_train[y_train==cat_dict[x]])\n",
    "print(\"Total Training Data: \"+str(train_sum)+\"\\n\")\n",
    "\n",
    "test_sum=0\n",
    "for x in categories:\n",
    "    print(x+\": \"+str(len(y_test[y_test==cat_dict[x]])))\n",
    "    test_sum+=len(y_test[y_test==cat_dict[x]])\n",
    "print(\"Total Test Data: \"+str(test_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ashley', 'Cole', 'has', 'refused', 'to', 'blame', 'Robin', 'van', 'Persie', 'for', 'leaving', 'Arsenal', 'with', 'no', 'fully', 'fit', 'strikers', 'for', 'the', 'FA', 'Cup', 'fifth', 'round', 'replay', 'at', 'Sheffield', 'United', 'Van', 'Persie', 'is', 'suspended', 'alongside', 'Dennis', 'Bergkamp', 'and', 'Jose', 'Antonio', 'Reyes', 'after', 'being', 'sent', 'off', 'at', 'Southampton', 'when', 'Arsenal', 'had', 'a', 'numerical', 'advantage', 'Thierry', 'Henry', 'is', 'ruled', 'out', 'with', 'an', 'Achilles', 'tendon', 'injury', 'but', 'Cole', 'said', 'No', 'one', 'is', 'putting', 'the', 'blame', 'on', 'Robin', 'It', 's', 'just', 'something', 'that', 'happens', 'on', 'the', 'spur', 'of', 'the', 'moment', 'Cole', 'added', 'I', 've', 'done', 'it', 'before', 'and', 'I', 'hope', 'they', 'didn', 't', 'blame', 'me', 'for', 'anything', 'Of', 'course', 'he', 'll', 'learn', 'I', 've', 'been', 'sent', 'off', 'a', 'couple', 'of', 'times', 'now', 'and', 'it', 's', 'just', 'one', 'of', 'those', 'things', 'when', 'you', 'go', 'a', 'bit', 'crazy', 'for', 'one', 'or', 'two', 'seconds', 'Freddie', 'Ljungberg', 'is', 'likely', 'to', 'be', 'used', 'in', 'an', 'emergency', 'striking', 'role', 'and', 'will', 'be', 'partnered', 'by', 'either', 'Arturo', 'Lupoli', 'Quincy', 'Owusu', 'Abeyie', 'or', 'Jeremie', 'Aliadiere', 'Gunners', 'boss', 'Arsene', 'Wenger', 'said', 'Freddie', 'is', 'an', 'option', 'but', 'we', 'need', 'a', 'second', 'striker', 'I', 'have', 'to', 'decide', 'whether', 'it', 'will', 'be', 'Aliadiere', 'Quincy', 'or', 'Lupoli', 'who', 'will', 'start', 'with', 'him', 'up', 'front', 'Those', 'three', 'will', 'be', 'involved', 'Arsenal', 'are', 'also', 'without', 'winger', 'Robert', 'Pires', 'who', 'sustained', 'an', 'ankle', 'injury', 'at', 'St', 'Mary', 's', 'Wenger', 'added', 'It', 'doesn', 't', 'look', 'like', 'anything', 'is', 'fractured', 'but', 'it', 'is', 'a', 'good', 'ankle', 'sprain', 'It', 'does', 'not', 'look', 'like', 'Pires', 'will', 'be', 'ready', 'for', 'two', 'to', 'three', 'weeks']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "X_train_notcleaned=[word_tokenize(i) for i in X_train]\n",
    "y_train=y_train.values\n",
    "X_test_notcleaned=[word_tokenize(i) for i in X_test]\n",
    "y_test=y_test.values\n",
    "\n",
    "print(X_train_notcleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ashley', 'Cole', 'refused', 'blame', 'Robin', 'van', 'Persie', 'leaving', 'Arsenal', 'fully', 'fit', 'strikers', 'Cup', 'fifth', 'round', 'replay', 'Sheffield', 'United', 'Van', 'Persie', 'suspended', 'alongside', 'Dennis', 'Bergkamp', 'Jose', 'Antonio', 'Reyes', 'sent', 'Southampton', 'Arsenal', 'numerical', 'advantage', 'Thierry', 'Henry', 'ruled', 'Achilles', 'tendon', 'injury', 'Cole', 'said', 'one', 'putting', 'blame', 'Robin', 'something', 'happens', 'spur', 'moment', 'Cole', 'added', 'done', 'hope', 'blame', 'anything', 'course', 'learn', 'sent', 'couple', 'times', 'one', 'things', 'bit', 'crazy', 'one', 'two', 'seconds', 'Freddie', 'Ljungberg', 'likely', 'used', 'emergency', 'striking', 'role', 'partnered', 'either', 'Arturo', 'Lupoli', 'Quincy', 'Owusu', 'Abeyie', 'Jeremie', 'Aliadiere', 'Gunners', 'boss', 'Arsene', 'Wenger', 'said', 'Freddie', 'option', 'need', 'second', 'striker', 'decide', 'whether', 'Aliadiere', 'Quincy', 'Lupoli', 'start', 'front', 'Those', 'three', 'involved', 'Arsenal', 'also', 'without', 'winger', 'Robert', 'Pires', 'sustained', 'ankle', 'injury', 'Mary', 'Wenger', 'added', 'look', 'like', 'anything', 'fractured', 'good', 'ankle', 'sprain', 'look', 'like', 'Pires', 'ready', 'two', 'three', 'weeks']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "X_train,X_test=[],[]\n",
    "for s in X_train_notcleaned:\n",
    "    s_cleaned = []\n",
    "    for w in s:\n",
    "        if w not in stopwords.words(\"english\") and len(w)>=3:\n",
    "            s_cleaned.append(w)\n",
    " \n",
    "    X_train.append(s_cleaned)\n",
    "for s in X_test_notcleaned:\n",
    "    s_cleaned = []\n",
    "    for w in s:\n",
    "        if w not in stopwords.words(\"english\") and len(w)>=3:\n",
    "            s_cleaned.append(w)\n",
    " \n",
    "    X_test.append(s_cleaned)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set([])\n",
    "for s in X_train:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words:25132\n",
      "1847\n",
      "[11704  3187 23251 ...     0     0     0]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "train_sentences_X, test_sentences_X = [], []\n",
    "\n",
    "EMB_DIM=300\n",
    "num_words=len(word2index)+1\n",
    "print(\"Number of Words:\"+str(num_words))\n",
    "\n",
    "for s in X_train:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    "    \n",
    "for s in X_test:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    "\n",
    "\n",
    "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
    "print(MAX_LENGTH)  # 271\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "print(train_sentences_X[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1847, 300)         7539600   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               439296    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 7,979,153\n",
      "Trainable params: 7,979,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, CuDNNLSTM,LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "model=Sequential() \n",
    "#embedding_layer=Embedding(num_words,EMB_DIM,embeddings_initializer=Constant(embedding_matrix),input_length=MAX_LENGTH,trainable=True)\n",
    "embedding_layer=Embedding(num_words, 300,mask_zero=True)\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(128,activation=\"tanh\")))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation=\"softmax\"))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(0.0001),    \n",
    "              metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1780 samples, validate on 445 samples\n",
      "Epoch 1/15\n",
      " 100/1780 [>.............................] - ETA: 7:27 - loss: nan - acc: 0.1500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d59433b66d41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtbCallBack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./Graph'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.003\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sentences_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sentences_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtbCallBack\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "es = EarlyStopping(monitor='val_acc', mode='max',verbose=1,patience=3,min_delta=0.003)\n",
    "history=model.fit(train_sentences_X, y_train, validation_data=(test_sentences_X,y_test), batch_size=64,epochs=15,callbacks=[es,tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
